{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predictify",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkabranov/predictify/blob/master/predictify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnIR0-kj8BcM",
        "colab_type": "code",
        "outputId": "57bddb11-638b-4077-fbbe-1e1c80dd7474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "#install dependencies\n",
        "!pip install spotipy --upgrade \n",
        "!pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: spotipy in /usr/local/lib/python3.6/dist-packages (2.12.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from spotipy) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from spotipy) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->spotipy) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->spotipy) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->spotipy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->spotipy) (2.9)\n",
            "Requirement already up-to-date: google-api-python-client in /usr/local/lib/python3.6/dist-packages (1.8.4)\n",
            "Requirement already up-to-date: google-auth-httplib2 in /usr/local/lib/python3.6/dist-packages (0.0.3)\n",
            "Requirement already up-to-date: google-auth-oauthlib in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client) (3.0.1)\n",
            "Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client) (0.17.3)\n",
            "Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client) (1.7.2)\n",
            "Requirement already satisfied, skipping upgrade: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client) (1.16.0)\n",
            "Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client) (46.4.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client) (1.51.0)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrYyNS9EnnYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imports for API request\n",
        "import json\n",
        "import spotipy as sp\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM-8AA7oPXSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imports for NN\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from torch import utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIlyfqjCdMQk",
        "colab_type": "code",
        "outputId": "806a180d-2e15-45db-e9c5-78d5c2b3e776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_VDinzUSi3z",
        "colab_type": "code",
        "outputId": "24fc5cfe-ee0e-414a-ea65-d2049a5fb593",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#Get authorization\n",
        "token = sp.oauth2.SpotifyClientCredentials(client_id='0ae72c9b0d4948d5ba0206c4c350d3fe', client_secret='c1db0c06c2df46b7b9219250080adc8d')\n",
        "cache_token = token.get_access_token()\n",
        "spotify = sp.Spotify(cache_token)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: You're using 'as_dict = True'.get_access_token will return the token string directly in future versions. Please adjust your code accordingly, or use get_cached_token instead.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULqVaLKdg9y-",
        "colab_type": "code",
        "outputId": "2c742093-41a2-4278-e16a-5c5099eb9a9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "spotify.user_playlist_tracks('pkabranov', '4Kvvbir7qtwhF5xIeRILOl', limit=15, offset=0).get('total')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1220"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtJxcETlfq0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get IDs in specified playlist \n",
        "\n",
        "def get_playlist_ids(playlist_id):\n",
        "  offset = 0\n",
        "  track_ids = []\n",
        "  while offset < spotify.user_playlist_tracks('pkabranov', playlist_id, offset=0).get('total'):\n",
        "    print(offset)\n",
        "    results = spotify.user_playlist_tracks('pkabranov', playlist_id, limit=1, offset=offset)\n",
        "    for item in results['items']:\n",
        "      if not item in track_ids: \n",
        "        track_ids.append(item['track']['id'])\n",
        "    offset += 1\n",
        "  return track_ids\n",
        "\n",
        "rishi_ids = get_playlist_ids('4Kvvbir7qtwhF5xIeRILOl')\n",
        "len(rishi_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPoo3ZckpENO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get usable features for each track in track_ids\n",
        "\n",
        "def get_playlist_features(track_ids):\n",
        "  all_feature_tracks = spotify.audio_features(track_ids)\n",
        "\n",
        "  usable_keys = ['duration_ms', 'id', 'key', 'loudness', 'tempo', 'time_signature']\n",
        "  usable_track_features = []\n",
        "\n",
        "  for track in all_feature_tracks:\n",
        "    if track:\n",
        "      usable_track_features.append({key: value for (key, value) in track.items() if key in usable_keys})\n",
        "\n",
        "  return usable_track_features\n",
        "\n",
        "batch, interval = 0, 10\n",
        "all_usable_track_features = []\n",
        "\n",
        "while batch < len(rapcaviar_ids) - interval:\n",
        "  all_usable_track_features.append(get_playlist_features(rapcaviar_ids[batch:(batch + interval)]))\n",
        "  print(all_usable_track_features)\n",
        "  batch += interval\n",
        "\n",
        "all_usable_track_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkYFQV7k3Gws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDHD1_7jd3xa",
        "colab_type": "code",
        "outputId": "2b7ab3d1-ebb8-4331-e78f-1b290bea8d38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def get_artist_song_ids():\n",
        "  with open('drive/My Drive/predictify/data_table_2.csv', newline='') as csvfile:\n",
        "      spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
        "      for row in spamreader:\n",
        "          url = urllib.parse.unquote(row[1] + \"%20artist:\" + row[0])\n",
        "          search_result = spotify.search(url, type='track', limit=1)\n",
        "          print(search_result.get('tracks')['items'][0]['artists'][0].get('name'), \n",
        "                \" | \" + search_result.get('tracks')['items'][0]['name'], \n",
        "                \" | \" + search_result.get('tracks')['items'][0]['id'], \n",
        "                \" | \" + row[2])\n",
        "          \n",
        "get_artist_song_ids()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drake  | Deep Pockets  | 3IvMYBE7A3c7to1aEcfFJk  | 12482146\n",
            "Drake  | When To Say When  | 5TCBWmEBrin7etRa4Lswr1  | 12885199\n",
            "Drake  | Chicago Freestyle (feat. Giveon)  | 4wVOKKEHUJxHCFFNUWDn0B  | 36258296\n",
            "Drake  | Not You Too (feat. Chris Brown)  | 3Q4gttWQ6hxqWOa3tHoTNi  | 15311250\n",
            "Drake  | Toosie Slide  | 127QTOFJsJQp5LbJbu3A1y  | 273281855\n",
            "Drake  | Desires (with Future)  | 7eYAHC0RbBF9eaqWzT34Aq  | 17211311\n",
            "Drake  | Time Flies  | 5H4mXWKcicuLKDn4Jy0sK7  | 17583595\n",
            "Drake  | Landed  | 3KixNgUEaDtrKJVzdqjU5q  | 14140426\n",
            "Drake White  | The Coast Is Clear (Live)  | 7HmS8eJdjfd5gUpckIzZvt  | 18655914\n",
            "Drake  | Pain 1993 (with Playboi Carti)  | 6Kj17Afjo1OKJYpf5VzCeo  | 38300275\n",
            "Drake  | Losses  | 6fLVTVaHWaEfVKfEgbkf4D  | 10611692\n",
            "Drake  | From Florida With Love  | 0YkUwXxnTkeJBvt5upeEtP  | 12005286\n",
            "Drake  | Demons (feat. Fivio Foreign & Sosa Geek)  | 05aZ9sAU1YXndHv0FMi9iW  | 18436544\n",
            "Drake  | War  | 1I55Ea0zVoSKs6MqW7DQ3i  | 13748085\n",
            "Drake  | Dreams Money Can Buy  | 1qyFlfPREPbRcS2BNszdYI  | 15269522\n",
            "Drake  | The Motion  | 0Tacxc5lDJ8LwiO1pWNSl8  | 40323757\n",
            "Drake  | How Bout Now  | 4n4BflhWjCHIxrI4v7Xt9s  | 23172564\n",
            "Drake  | Trust Issues  | 4Wjhj0WjkyECccfHVIgaTq  | 27548048\n",
            "Drake  | Days in The East  | 4czcw3NVLY0of5hTD7OufN  | 11252896\n",
            "Drake  | Draft Day  | 3W3FVHEDetkiRkkGKDmdir  | 9764523\n",
            "Drake  | 4pm in Calabasas  | 6C9SwoZ5OrxcvkntgA5t8s  | 13510964\n",
            "Drake  | 5 Am in Toronto  | 0FnxK9FEAQyPJ284QcieNb  | 12415951\n",
            "Drake  | I Get Lonely  | 3sMC6vfTTSa0mMAPTwzDVD  | 9838006\n",
            "Drake  | My Side  | 4alHkxxwAhvoGg3dJCATKV  | 7401214\n",
            "Drake  | Jodeci Freestyle (feat. J. Cole)  | 2xUHiyGeGrWmmfv7NbDTWC  | 8451550\n",
            "Drake  | Club Paradise  | 6MR5IBSNfDmiwnrlQpVw4w  | 10510249\n",
            "Drake  | Free Spirit (feat. Rick Ross)  | 18t8ypY0HYaQuGBxg2KdT2  | 7321923\n",
            "Drake  | Heat Of The Moment  | 27Tqjd2nMW2mIp6Yk1ovwY  | 5149715\n",
            "Drake  | Girls Love Beyoncé (feat. James Fauntleroy)  | 56NDFbD0tCUawnqeU2wcvv  | 18533798\n",
            "Drake  | Pound Cake / Paris Morton Music 2  | 4NVNapccSX7E5JLiW0uQEy  | 9489121\n",
            "Drake  | Can I  | 3e0ZGE7Gp034iLknjQk4QW  | 10480228\n",
            "Drake  | Survival  | 2yg9UN4eo5eMVJ7OB4RWj3  | 90297431\n",
            "Drake  | Nonstop  | 0TlLq3lA83rQOYtrqBqSct  | 639167338\n",
            "Drake  | Elevate  | 3szf2z1Cy1QMrtHrbn8rz9  | 119424757\n",
            "Drake  | Emotionless  | 5Psnhdkyanjpgc2P8A5TSM  | 128698471\n",
            "Drake  | God's Plan  | 6DCZcSspjsKoFjzjrWoCdn  | 1539119025\n",
            "Drake  | I'm Upset  | 3qN5qMTKyEEmiTZD38BNTT  | 301232744\n",
            "Drake  | 8 Out Of 10  | 0zqy3ss4CwD6u4QPksS0nI  | 90921212\n",
            "Drake  | Mob Ties  | 7rC5Pl8rQSX4myONQHYPBK  | 231745654\n",
            "Drake  | Can’t Take A Joke  | 1dUHF4RyMmMTveJ0Rby6Xm  | 127929195\n",
            "Drake  | Sandra’s Rose  | 6cblRiEGDRNZgowcm951R3  | 77851941\n",
            "Drake  | Talk Up (feat. Jay-Z)  | 4ksuI04WMvUnJbHQjgs3L5  | 83214093\n",
            "Drake  | Is There More  | 1Tnw0ItH1Macok8gblnPPd  | 58881611\n",
            "Drake  | Peak  | 11L064movtyopGdLiX4sVg  | 67311088\n",
            "Drake  | Summer Games  | 4HG1YiGBseVKzjyKcmAJen  | 80913744\n",
            "Drake  | Jaded  | 4c2xt1trwYZpMqPWY35Xi9  | 94767533\n",
            "Drake  | Nice For What  | 3CA9pLiwRIGtUBiMjbZmRw  | 809177848\n",
            "Drake  | Finesse  | 2WP8G2pdddDmnh1xbfKBOI  | 96858081\n",
            "Drake  | Ratchet Happy Birthday  | 4SUwJA3eUVNHExxMPEUhQe  | 54110154\n",
            "Drake  | That’s How You Feel  | 41a7dZcq30Ss5kPMayWRV0  | 79439187\n",
            "Drake  | Blue Tint  | 4n1bdaKwynQndm47x5HqWX  | 96814309\n",
            "Drake  | In My Feelings  | 2G7V7zsVDxg1yRsu7Ew9RJ  | 1017175142\n",
            "Drake  | Don’t Matter To Me (with Michael Jackson)  | 6G8kHiVZ1jW7vHMPVRNZU0  | 354925483\n",
            "Drake  | After Dark (feat. Static Major & Ty Dolla $ign)  | 3mvYQKm8h6M5K5h0nVPY9S  | 83656903\n",
            "Drake  | Final Fantasy  | 44Du2IM1bGY7dicmLfXbUs  | 83656903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-bfad1126b90e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \" | \" + row[2])\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mget_artist_song_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-108-bfad1126b90e>\u001b[0m in \u001b[0;36mget_artist_song_ids\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munquote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"%20artist:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0msearch_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspotify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'track'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           print(search_result.get('tracks')['items'][0]['artists'][0].get('name'), \n\u001b[0m\u001b[1;32m      8\u001b[0m                 \u001b[0;34m\" | \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msearch_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tracks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'items'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0;34m\" | \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msearch_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tracks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'items'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VklcruC-5qR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import and format data\n",
        "\n",
        "Dataloader()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84KRbbyJQHEn",
        "colab_type": "code",
        "outputId": "83e10826-1fc7-447c-b27f-c8f1b2deda50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#Define architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.advance = nn.Sequential(nn.Linear(5, 5),\n",
        "                                     nn.ReLU(),\n",
        "                                     nn.Linear(5, 5),\n",
        "                                     nn.ReLU(),\n",
        "                                     nn.Linear(5, 5),\n",
        "                                     nn.Softmax()\n",
        "                                    )\n",
        "        print(self)\n",
        "\n",
        "    def forward(self, features):\n",
        "        output = self.advance(features.float())\n",
        "        return output\n",
        "\n",
        "net = Net()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (advance): Sequential(\n",
            "    (0): Linear(in_features=5, out_features=5, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=5, out_features=5, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=5, out_features=5, bias=True)\n",
            "    (5): Softmax(dim=None)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-Y_pyH4YSTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import functools\n",
        "\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLQ45AM27P7V",
        "colab_type": "text"
      },
      "source": [
        "Load the data from csv file URLS and visualize:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBUMfGLN7NsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_DATA_URL = \".csv\" #.csv file url for train data\n",
        "TEST_DATA_URL = \".csv\" #csv file url for test data\n",
        "\n",
        "train_file_path = tf.keras.utils.get_file(\"train.csv\", TRAIN_DATA_URL)\n",
        "test_file_path = tf.keras.utils.get_file(\"test.csv\", TEST_DATA_URL)\n",
        "\n",
        "LABEL_COLUMN = 'popularity_score' #the column name of the value the model predicts\n",
        "LABELS = [0, 1]\n",
        "\n",
        "#load dataset\n",
        "def get_dataset(file_path, **kwargs):\n",
        "    dataset = tf.data.experimental.make_csv_dataset(\n",
        "        file_path,\n",
        "        batch_size = , #insert batch size\n",
        "        label_name = LABEL_COLUMN,\n",
        "        num_epochs = 1,\n",
        "        ignore_errors = True,\n",
        "        **kwargs)\n",
        "    return dataset\n",
        "\n",
        "raw_train_data = get_dataset(train_file_path)\n",
        "raw_test_data = get_dataset(test_file_path) \n",
        "\n",
        "#visualize dataset\n",
        "def show_batch(dataset):\n",
        "    for batch, label in dataset.take(1):\n",
        "        for key, value in batch.items():\n",
        "            print(\"{:10s}: {}\".format(key,value.numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhsrRdwz8cU6",
        "colab_type": "text"
      },
      "source": [
        "Organize the data into continuous and categorical data (i dont think we have cat data) that cna be analyzed #assume that the csv file has the labels already on the first row, otherwise pass it in \n",
        "`make_csv_dataset`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFdoftQr84Er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SELECT_COLUMNS = ['duration_ms', 'key', 'loudness', 'tempo', 'time_signature'] #omit the ID column\n",
        "DEFAULTS = [0.0, 0, 0.0, 0.0, 0]\n",
        "\n",
        "temp_dataset = get_dataset(train_file_path, select_columns=SELECT_COLUMNS, column_defaults = DEFAULTS)\n",
        "show_batch(temp_dataset) #visualization, can remove\n",
        "\n",
        "#pack the numerical data into vectors prior to preprocessing\n",
        "class PackNumericFeatures(object):\n",
        "  def __init__(self, names):\n",
        "    self.names = names\n",
        "\n",
        "  def __call__(self, features, labels):\n",
        "    numeric_features = [features.pop(name) for name in self.names]\n",
        "    numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_features]\n",
        "    numeric_features = tf.stack(numeric_features, axis=-1)\n",
        "    features['numeric'] = numeric_features\n",
        "\n",
        "    return features, labels\n",
        "\n",
        "NUMERIC_FEATURES = SELECT_COLUMNS\n",
        "\n",
        "packed_train_data = raw_train_data.map(PackNumericFeatures(NUMERIC_FEATURES))\n",
        "packed_test_data = raw_test_data.map(PackNumericFeatures(NUMERIC_FEATURES))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmQIl60VDKIy",
        "colab_type": "text"
      },
      "source": [
        "Perform some sort of data preprocessing on the continuous data (something basic rn like normalization or mean subtraction) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2iMxWtRJfDc",
        "colab_type": "text"
      },
      "source": [
        "Time signature and key are categorical data. Key ranges from -1 to 12 in the following manner:\n",
        "\n",
        "Key: -1: No key \n",
        "     0: C major\n",
        "     1: C# major\n",
        "\n",
        "**ISSUE:** All values of time signature aren't known\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hO5jGQiDNY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Continuous data\n",
        "desc = pd.read_csv(train_file_path)[NUMERIC_FEATURES].describe()\n",
        "desc #visualize our song data in pandas table\n",
        "\n",
        "MEAN = np.array(desc.T['mean'])\n",
        "STD = np.array(desc.T['std'])\n",
        "\n",
        "def normalize_numeric_data(data, mean, std):\n",
        "  # Center the data\n",
        "  return (data-mean)/std\n",
        "normalizer = functools.partial(normalize_numeric_data, mean=MEAN, std=STD)\n",
        "\n",
        "numeric_column = tf.feature_column.numeric_column('numeric', normalizer_fn=normalizer, shape=[len(NUMERIC_FEATURES)])\n",
        "numeric_columns = [numeric_column]\n",
        "numeric_columns\n",
        "\n",
        "#Categorical data \n",
        "CATEGORIES = {\n",
        "    'key': ['-1', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'],\n",
        "    'time_signature' : ['3', '4'],\n",
        "}\n",
        "categorical_columns = []\n",
        "for feature, vocab in CATEGORIES.items():\n",
        "  cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "        key=feature, vocabulary_list=vocab)\n",
        "  categorical_columns.append(tf.feature_column.indicator_column(cat_col))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9sgJcziX1il",
        "colab_type": "text"
      },
      "source": [
        "Soem layers for use in the net with the preprocessed data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur86U-DDXdoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns+numeric_columns)\n",
        "tf.keras.layers.Dense(1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2MoGglMZG_A",
        "colab_type": "text"
      },
      "source": [
        "Downloading spotify songs from a playlist as MP3s for potential waveform analysis "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL-PM4p8ZOkd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fy3dR-zaVMWv",
        "colab_type": "text"
      },
      "source": [
        "I think that the best way to store data would be to write it into a google sheet that's easily accessible so I'm trying to do that here\n",
        "\n",
        "TO-DO: \n",
        "\n",
        "1.   put the credentials.json file into the path (wehre tf is the path for google drive)\n",
        "2.   make sure dataframes are the correct types (im not sure what the spotify.user_playlist_tracks return type is, but format the pandas df into a convenient datatype) -- like can i put the return of this_iter_track_ids into a pd dataframe without any dtype conversions smoothly?\n",
        "3. make sure the update_cells usage is correct for pygsheets\n",
        "3.   get_track_features method\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVVfYhTqRkDI",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2OJixIKVGW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pygsheets\n",
        "import pandas as pd\n",
        "\n",
        "'''\n",
        "Access tokens here\n",
        "'''\n",
        "\n",
        "USERNAME = ''\n",
        "PLAYLIST_ID = ''\n",
        "\n",
        "#auth\n",
        "gc = pygsheets.authorize(service_file='drive/My Drive/predictify/predictify-data-a664cf501a42.json') #fill in the credentials.json here\n",
        "\n",
        "#open the sheet\n",
        "sh = gc.open('Song Data')\n",
        "wks = sh[0]\n",
        "#method that stores the data as a pandas dataframe and then shoves the dataframe into the google sheets\n",
        "def get_track_ids(username, playlist_id):\n",
        "  OFFSET = 0\n",
        "  track_ids = pd.Dataframe() #dataframe init\n",
        "  for i in range(spotify.user_playlist_tracks(USERNAME, PLAYLIST_ID, fields = total): #for the number of tracks in the playlist ID, offset increases by 100 every time\n",
        "    this_iter_track_ids = spotify.user_playlist_tracks(USERNAME, PLAYLIST_ID, limit = 100, OFFSET)\n",
        "    track_ids = track_ids.append(this_iter_track_ids)\n",
        "    OFFSET += 100\n",
        "  track_ids = pd.concat(track_ids, ignore_index = True)\n",
        "  #update the first sheet with df, starting at cell A2.\n",
        "  return track_ids\n",
        "\n",
        "#extract the track ids from either the initial pd dataframe or the google sheet and use it to get song features, then store the features into df and google sheets\n",
        "def get_track_features(username, track_ids):\n",
        "  track_features = pd.Dataframe() #dataframe init\n",
        "  keys = ['duration_ms', 'id', 'key', 'loudness', 'tempo', 'time_signature']\n",
        "  for i in range(len(get_track_ids(USERNAME, PLAYLIST_ID).index)):\n",
        "    #append the data into track_features\n",
        "    this_iter_track_features = track_features.append({key: value for (key, value in track.items() if key in keys)})\n",
        "  return track_features\n",
        "\n",
        "column_data = [get_track_ids(), get_track_features()]\n",
        "complete_data = pd.concat(column_data)\n",
        "wks.set_dataframe(complete_data, (2, 1), extend = True, escape_formulae = True)\n",
        "wks.export(filetype = 'csv', filename = 'SongData')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}